# Distinguishing PULSAR from Existing Papers Referred by the Reviewer

**Rocha et al. (RGB-D Gait Analysis):** This work targets gait analysis using specialized Kinect hardware in controlled hospital environments, evaluating only 6 participants (3 PD patients with DBS implants) for post-diagnosis monitoring rather than screening. PULSAR addresses a completely different challenge: home-based screening using standard webcams without requiring walking space, specialized equipment, or clinical supervision. Our focus on finger-tapping targets bradykinesia—a mandatory diagnostic criterion—while their gait analysis addresses different motor symptoms that may not be present in early-stage PD.

**Sibley et al. (Video Assessment Review):** This comprehensive review identified critical limitations in video-based MDS-UPDRS assessment, particularly poor agreement for bradykinesia evaluation due to human rating difficulties. PULSAR directly addresses these limitations by eliminating human rating dependency through automated graph-based learning. Our multi-stream architecture captures velocity and acceleration patterns that human raters struggle to quantify consistently, transforming the identified challenges into technical solutions.

**Jin et al. (Facial Expression Recognition):** This work focuses exclusively on facial "masked face" symptoms, achieving impressive results (F1: 99%) in a completely different symptom domain. PD patients may exhibit varying symptoms—some show facial changes while others primarily display motor symptoms. PULSAR targets bradykinesia through finger-tapping, addressing a mandatory diagnostic criterion that complements rather than competes with facial analysis. The approaches target different PD manifestations and could potentially be combined for comprehensive assessment.

**Vignoud et al. (MDS-UPDRS Video Assessment):** While this work also analyzes finger-tapping, it focuses on clinical severity scoring (coefficients of determination: 0.609-0.701) with fixed webcam setups and trained raters. PULSAR addresses binary screening without clinical supervision. Our key technical innovations—adaptive graph convolutions that learn task-specific relationships, multi-stream processing for movement dynamics, and PU learning for uncertain labels—target the fundamentally different challenge of population screening where clinical validation is unavailable.

**Brien et al. (Eye Tracking Classification):** This large-scale study (227 participants) achieved excellent results (AUC: 0.88-0.95, sensitivity: 83%, specificity: 78%) through eye movement analysis. However, eye tracking targets neurological circuits different from motor symptoms and requires participants to follow complex visual tasks that may be challenging for elderly populations or those with visual impairments. PULSAR focuses on motor assessment through simple finger movements, targeting different aspects of PD pathology and addressing accessibility constraints that eye tracking approaches cannot overcome.

**Lu et al. (Motor Severity Under Uncertainty):** This work addresses inter-rater variability in clinical settings (72% accuracy with majority vote, ~84% predicting any rater) using multiple expert ratings. PULSAR targets a fundamentally different scenario where clinical ratings are entirely unavailable. Our PU learning eliminates the need for any clinical validation, enabling screening in completely unsupervised settings where trained raters are inaccessible.

**PULSAR's Unique Contribution:** These works collectively demonstrate the diverse manifestations of PD and the variety of assessment approaches needed. PULSAR specifically addresses the critical gap in accessible screening for underserved populations, introducing adaptive graph learning for home-recorded videos and PU learning for self-reported data. Our 71.29% accuracy in completely unsupervised screening represents a significant advancement toward democratizing PD assessment, complementing rather than competing with existing clinical approaches.
